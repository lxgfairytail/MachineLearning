{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "class ID3DTree:\n",
    "    def __init__(self):\n",
    "        # 构造的树\n",
    "        self.tree = {}\n",
    "        # 数据集\n",
    "        self.dataSet = []\n",
    "        # 特征集的标签名字\n",
    "        self.labels = []\n",
    "        \n",
    "    def loadDataSet(self,path,feature_names):\n",
    "        recordlist = []\n",
    "        fp = open(path,'rb')\n",
    "        content = fp.read().decode('utf-8')\n",
    "        fp.close()\n",
    "        rowlist = content.splitlines() \t# 按行转换为一维表\n",
    "        recordlist = [row.split('\\t') for row in rowlist if row.strip()]\n",
    "        self.dataSet = recordlist\n",
    "        self.feature_names = feature_names\n",
    "        return self.dataSet,feature_names\n",
    "        \n",
    "    def train(self):\n",
    "        feature_names = deepcopy(self.feature_names)\n",
    "        self.tree = self.buildTree(self.dataSet,feature_names)\n",
    "    \n",
    "    def buildTree(self,dataSet,feature_names):\n",
    "        # 抽取源数据集的决策分类标签列\n",
    "        catelist = [data[-1] for data in dataSet]\n",
    "        \n",
    "        # 终止条件1：只有一个类别标签返回这个决策标签\n",
    "        if catelist.count(catelist[0]) == len(catelist):\n",
    "            return catelist[0]\n",
    "        # 终止条件2：如果没有特征可以划分，返回决策标签中最多的一类\n",
    "        if len(dataSet[0]) == 1:\n",
    "            return self.maxCate(catelist)\n",
    "        \n",
    "        # 算法核心\n",
    "        # 获取最好的特征所在的列\n",
    "        bestFeatureIndex = self.getBestFeature(dataSet)\n",
    "        bestFeatureName = feature_names[bestFeatureIndex]\n",
    "        tree = {bestFeatureName:{}}\n",
    "        del feature_names[bestFeatureIndex]\n",
    "        \n",
    "        # 抽取最优特征轴的列向量,及该最优特征有多少个属性值\n",
    "        uniqueVals = set([data[bestFeatureIndex] for data in dataSet])\n",
    "        # 决策树递归生长\n",
    "        for value in uniqueVals:\n",
    "            # 将删除后的特征类别集建立子类别集\n",
    "            sub_feature_names = feature_names[:]\n",
    "            # 按最优特征列和值分割数据集\n",
    "            splitDataSet = self.splitDataSet(dataSet,bestFeatureIndex,value)\n",
    "            # 构建子树 \n",
    "            subTree = self.buildTree(splitDataSet,sub_feature_names)\n",
    "            tree[bestFeatureName][value] = subTree\n",
    "        return tree\n",
    "     \n",
    "    # 计算数量最多的类别标签\n",
    "    def maxCate(self,catelist):\n",
    "        items = dict([(catelist.count(i),i) for i in catelist])\n",
    "        return items[max(items.keys())]\n",
    "    \n",
    "    # 计算最优特征所在的列\n",
    "    def getBestFeature(self,dataSet):\n",
    "        # 计算特征向量的维数\n",
    "        numFeatures = len(dataSet[0]) - 1\n",
    "        # 计算基础熵 H(D)\n",
    "        BaseEntropy = self.computeEntropy(dataSet)\n",
    "        # 初始化最好的信息增益\n",
    "        bestInfoGain = 0.0\n",
    "        # 初始化最优特征轴\n",
    "        bestFeatureIndex = -1\n",
    "        # 外循环：遍历数据集各列,计算最优特征轴; i为数据集列索引：取值范围 0~(numFeatures-1)\n",
    "        for i in range(numFeatures):\n",
    "            # 存储特征的属性值\n",
    "            uniqueVals = set([data[i] for data in dataSet])\n",
    "            # 初始化该列的香农熵\n",
    "            newEntropy = 0.0\n",
    "            # 内循环：按特征列和特征属性计算香农熵\n",
    "            for value in uniqueVals:\n",
    "                # 按选定列i和唯一值分隔数据集\n",
    "                subDataSet = self.splitDataSet(dataSet, i, value)\n",
    "                # 该特征属性在该特征中占比\n",
    "                prob = len(subDataSet)/float(len(dataSet))\n",
    "                # 计算在已知某特征的情况下的信息熵H（D|A）,\n",
    "                newEntropy += prob * self.computeEntropy(subDataSet)\n",
    "            # 计算信息增益\n",
    "            InfoGain = BaseEntropy - newEntropy\n",
    "            # 信息增益大于当前最好的信息增益，将其赋值给bestInfoGain,并记录最大信息增益对应的特征轴\n",
    "            if InfoGain > bestInfoGain:\n",
    "                bestInfoGain = InfoGain\n",
    "                bestFeatureIndex = i\n",
    "                \n",
    "        return bestFeatureIndex\n",
    "    \n",
    "    # 计算信息熵\n",
    "    def computeEntropy(self,dataSet):\n",
    "        datalen = float(len(dataSet))\n",
    "        # 抽取数据集的类别列\n",
    "        catelist = [data[-1] for data in dataSet]\n",
    "        # 统计每一类出现次数\n",
    "        items = dict([(i,catelist.count(i)) for i in catelist])\n",
    "        # 初始化信息熵\n",
    "        InfoEntropy = 0.0\n",
    "        # 计算信息熵\n",
    "        for key in items:\n",
    "            prob = items[key]/datalen\n",
    "            InfoEntropy -= prob * np.log2(prob)\n",
    "            \n",
    "        return InfoEntropy\n",
    "    \n",
    "    # 划分数据集，dataSet：数据集; axis：特征轴; value：特征轴的取值\n",
    "    def splitDataSet(self,DataSet,axis,value):\n",
    "        subDataSet = []\n",
    "        for feature_vector in DataSet:\n",
    "            if feature_vector[axis] == value:\n",
    "                sub_feature_vector = feature_vector[:axis]\n",
    "                sub_feature_vector.extend(feature_vector[axis+1:])\n",
    "                subDataSet.append(sub_feature_vector)\n",
    "        return subDataSet\n",
    "    \n",
    "    # 数据预测\n",
    "    def predict(self,InputTree,feature_names,testdata):\n",
    "        # 根节点\n",
    "        root = list(InputTree.keys())[0]\n",
    "        # value-子树结构或分类标签\n",
    "        secondDict = InputTree[root]  \n",
    "        # 节点在特征中的位置\n",
    "        feature_index = feature_names.index(root)\n",
    "        # 节点的特征属性取值\n",
    "        key = testdata[feature_index]\n",
    "        # 该特征取值对应的子树结构或分类标签\n",
    "        valueOfFeat = secondDict[key] \n",
    "        # 判断取值为子树结构还是标签\n",
    "        if isinstance(valueOfFeat,dict):\n",
    "            classLabel = self.predict(valueOfFeat,feature_names,testdata)\n",
    "        else:\n",
    "            classLabel = valueOfFeat\n",
    "        return classLabel\n",
    "    \n",
    "    # 持久化\n",
    "    # 存储树到文件\n",
    "    def storeTree(self,inputTree,filename):\n",
    "        fw = open(filename,'wb')\n",
    "        pickle.dump(inputTree,fw)\n",
    "        fw.close()\n",
    "        \n",
    "    # 从文件抓取树    \n",
    "    def grabTree(self,filename):\n",
    "        fr = open(filename,'rb')\n",
    "        tree = pickle.load(fr)\n",
    "        fr.close()\n",
    "        return tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {'1': 'yes', '2': {'credit': {'1': 'no', '0': 'yes'}}, '0': {'student': {'1': 'yes', '0': 'no'}}}}\n",
      "(1024, 5)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "from numpy import * \n",
    "# import treePlotter2\n",
    "\n",
    "# 创建决策树\n",
    "dtree = ID3DTree() \n",
    "# [\"age\",\"revenue\",\"student\",\"credit\"] 对应 年龄、收入、学生、信誉 四个特征\n",
    "dataSet,feature_names = dtree.loadDataSet(\"dataset.dat\",[\"age\",\"revenue\",\"student\",\"credit\"]) \n",
    "dtree.train() \n",
    "print(dtree.tree)\n",
    "print(shape(dataSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {'1': 'yes', '2': {'credit': {'1': 'no', '0': 'yes'}}, '0': {'student': {'1': 'yes', '0': 'no'}}}}\n"
     ]
    }
   ],
   "source": [
    "# 决策树持久化\n",
    "dtree.storeTree(dtree.tree,\"ID3DTree\")\n",
    "mytree = dtree.grabTree(\"ID3DTree\")\n",
    "print(mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真实输出  no -> 决策树输出 no\n"
     ]
    }
   ],
   "source": [
    "# 使用决策树预测\n",
    "labels = [\"age\",\"revenue\",\"student\",\"credit\"]\n",
    "vector = ['2','0','0','1']\n",
    "print(\"真实输出 \",\"no\",\"->\",\"决策树输出\",dtree.predict(mytree,labels,vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
