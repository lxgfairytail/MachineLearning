{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "def loadDataSet():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him','my'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = ['a','b','a','b','a','b']    # 1 is abusive, 0 not\n",
    "    return postingList,classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = []     # 存储词汇表\n",
    "        self.vocabulary_length = 0\n",
    "        self.tf = 0\n",
    "        self.idf = 0\n",
    "        self.tdm = {}             # 存储 P(x|yi) \n",
    "        self.labels = []\n",
    "        self.doc_length = 0\n",
    "        self.Pcategory = {}\n",
    "        \n",
    "    def fit(self,DataSet,labels):\n",
    "        self.doc_length = len(DataSet)\n",
    "        vocabulary_set = set()\n",
    "        [vocabulary_set.add(word) for doc in DataSet for word in doc]\n",
    "        self.vocabulary = list(vocabulary_set)\n",
    "        print(self.vocabulary)\n",
    "        self.vocabulary_length = len(self.vocabulary)\n",
    "        self.labels = labels\n",
    "        self.CalcPcategory()\n",
    "        self.CalcWordFreq(DataSet)\n",
    "        self.Build_tdm()\n",
    "    \n",
    "    def CalcPcategory(self):\n",
    "        category_set = set(self.labels)\n",
    "        for label in category_set:\n",
    "            self.Pcategory[label] = self.labels.count(label)/len(self.labels)\n",
    "    \n",
    "    def CalcWordFreq(self,DataSet):\n",
    "        self.tf = np.zeros([self.doc_length,self.vocabulary_length])\n",
    "        self.idf = np.zeros([1,self.vocabulary_length])\n",
    "        \n",
    "        for i in range(self.doc_length):\n",
    "            for j in range(self.vocabulary_length):\n",
    "                self.tf[i,j] = (DataSet[i].count(self.vocabulary[j]) + 0.1)/(len(DataSet[i]) + 0.1)\n",
    "            for word in set(DataSet[i]):\n",
    "                self.idf[0,self.vocabulary.index(word)] += 1\n",
    "                \n",
    "        self.idf = np.log(float(self.doc_length)/self.idf)\n",
    "        self.tf = np.multiply(self.tf,self.idf)  # 矩阵与向量的点乘 tf x idf\n",
    "    \n",
    "    def Build_tdm(self):\n",
    "        sumtf ={}\n",
    "        for label in self.Pcategory:\n",
    "            self.tdm[label] = np.zeros([1,self.vocabulary_length])\n",
    "            sumtf[label] = np.zeros([1,1])\n",
    "        for i in range(self.doc_length):\n",
    "            self.tdm[self.labels[i]] += self.tf[i] # 将同一类别的词向量空间值加总\n",
    "            # 统计每个分类的总值--是个标量\n",
    "            sumtf[self.labels[i]]= np.sum(self.tdm[self.labels[i]])\n",
    "        for label in self.tdm:\n",
    "            self.tdm[label] /= sumtf[label]\n",
    "        \n",
    "    def predict(self,TestSet):\n",
    "        test_tf = np.zeros([len(TestSet),self.vocabulary_length])\n",
    "        for i in range(len(TestSet)):\n",
    "            for j in range(self.vocabulary_length):\n",
    "                test_tf[i,j] = TestSet[i].count(self.vocabulary[j])\n",
    "       \n",
    "        predclass = [] # 初始化类别名称\n",
    "        for i in range(len(test_tf)):\n",
    "            predvalue = -float('inf') # 初始化类别概率 \n",
    "            predclass_temp = ''\n",
    "            for keyclass in self.Pcategory.keys():\n",
    "                # P(x|yi) P(yi)\n",
    "                temp = np.sum(test_tf[i]*np.log(self.tdm[keyclass]) + np.log(self.Pcategory[keyclass])) # 变量tdm，计算最大分类值\n",
    "                if temp > predvalue:\n",
    "                    predvalue = temp\n",
    "                    predclass_temp = keyclass\n",
    "            predclass.append(predclass_temp)\n",
    "        return predclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him', 'my'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
      "['a', 'b', 'a', 'b', 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "dataset, labels = loadDataSet()\n",
    "print(dataset)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stop', 'please', 'so', 'buying', 'steak', 'dog', 'garbage', 'problems', 'how', 'flea', 'ate', 'has', 'help', 'him', 'park', 'not', 'take', 'worthless', 'dalmation', 'my', 'cute', 'licks', 'food', 'posting', 'is', 'maybe', 'mr', 'I', 'to', 'stupid', 'love', 'quit']\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.fit(dataset,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'a', 'b', 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "a = nb.predict(dataset)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
